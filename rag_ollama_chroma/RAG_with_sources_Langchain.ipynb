{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5efb44b5-ffd8-4846-bf43-0baba85c4738",
   "metadata": {},
   "source": [
    "## Example of querying a set of documents with sources using Caikit-TGIS with Llama2, Langchain and a custom prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a196e07-7980-43f3-906e-7373367fe896",
   "metadata": {},
   "source": [
    "### Set the Inference server url (replace with your own address) and the model-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aaedb0b-4a37-418e-9608-8abcc819f87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server_url = \"http://ollama.redis.svc.cluster.local:11434\"\n",
    "model_id = \"Llama-2-7b-chat-hf\"\n",
    "\n",
    "# If your endpoint is using a self-signed certificate, export the certificate chain as a .pem file and provide its path\n",
    "# Example: certificate_chain = \"certificate.pem\"\n",
    "# Adjust llm instantiation to use this parameter or not\n",
    "certificate_chain_file = \"certificate.pem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a83a615-62f4-4fcf-924c-a9096a3d511c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional, requirements if they are not already present\n",
    "# !pip -q install grpcio grpcio-reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fbc3e3-6612-49eb-b07e-710e27f4d2df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load some data from the folder where we have stored the PDF documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31f9b89-3613-42fc-aa6f-683ac78accff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "pdf_folder_path = 'rhods-doc'\n",
    "\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4547b1-4dea-4c08-ad79-c70186f25611",
   "metadata": {},
   "source": [
    "### Split the data in chunks large enough to have meaningful answers, and some overlap not to miss anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7a68c1-2308-410e-b50f-9270c00b1d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1024, chunk_overlap = 40)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e32e34-aa32-4a57-b4ac-3e2e490b1be6",
   "metadata": {},
   "source": [
    "### Store the data as embeddings in a vector database (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af325249-120a-49e4-be21-5b902e054819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to connect optimized C data functions [No module named '_testbuffer'], falling back to pure Python\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m----> 4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain/vectorstores/chroma.py:646\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    645\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain/vectorstores/chroma.py:610\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03mIf a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    602\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m    603\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    609\u001b[0m )\n\u001b[0;32m--> 610\u001b[0m \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain/vectorstores/chroma.py:237\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    232\u001b[0m             embeddings\u001b[38;5;241m=\u001b[39membeddings_without_metadatas,\n\u001b[1;32m    233\u001b[0m             documents\u001b[38;5;241m=\u001b[39mtexts_without_metadatas,\n\u001b[1;32m    234\u001b[0m             ids\u001b[38;5;241m=\u001b[39mids_without_metadatas,\n\u001b[1;32m    235\u001b[0m         )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/chromadb/api/models/Collection.py:298\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, increment_index)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m     increment_index: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     ids, embeddings, metadatas, documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n\u001b[1;32m    303\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    304\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m         increment_index\u001b[38;5;241m=\u001b[39mincrement_index,\n\u001b[1;32m    309\u001b[0m     )\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/chromadb/api/models/Collection.py:350\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, require_embeddings_or_documents)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    339\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     Optional[List[Document]],\n\u001b[1;32m    349\u001b[0m ]:\n\u001b[0;32m--> 350\u001b[0m     ids \u001b[38;5;241m=\u001b[39m validate_ids(\u001b[43mmaybe_cast_one_to_many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    351\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    352\u001b[0m         validate_embeddings(maybe_cast_one_to_many(embeddings))\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    357\u001b[0m         validate_metadatas(maybe_cast_one_to_many(metadatas))\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     )\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/chromadb/api/types.py:99\u001b[0m, in \u001b[0;36mmaybe_cast_one_to_many\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [target]\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# One Embedding\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [target]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# One Metadata dict\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34903f71-99cc-4d4d-a97a-dc530e9c5a47",
   "metadata": {},
   "source": [
    "### Test data retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47f639-98bc-4f59-b6b6-56e01affb708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"How do I create a Data Science Project\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4dd9a-9ac0-407a-9455-0a5906aa9ed3",
   "metadata": {},
   "source": [
    "### Create the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3cceb-2c39-4a74-bf72-a733b22dfd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "import caikit_tgis_langchain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# NOTE: This template syntax is specific to Llama2\n",
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant.\n",
    "You will be given a question you need to answer, and a context to provide you with information. You must answer the question based as much as possible on this context.\n",
    "Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Question: {question}\n",
    "Context: {context} [/INST]\n",
    "\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = caikit_tgis_langchain.CaikitLLM(\n",
    "    inference_server_url=inference_server_url,\n",
    "    model_id=model_id,\n",
    "    certificate_chain=certificate_chain_file,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectorstore.as_retriever(),\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "                                       return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03510738-5704-4b56-9ce8-db99d0259757",
   "metadata": {},
   "source": [
    "### Launch the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26a45d-7953-42cb-aab5-cf2e8c63213d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"How do I create a Data Science Project?\"\n",
    "result = qa_chain({\"query\": question, \"min_new_tokens\": 100, \"max_new_tokens\": 1024}, callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b28ac-a3ab-462c-add7-e5473eaea92f",
   "metadata": {},
   "source": [
    "### Print the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07166717-6b89-47de-baab-f91695602e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    unique_list = []\n",
    "    for item in input_list:\n",
    "        if item.metadata['source'] not in unique_list:\n",
    "            unique_list.append(item.metadata['source'])\n",
    "    return unique_list\n",
    "\n",
    "results = remove_duplicates(result['source_documents'])\n",
    "\n",
    "for s in results:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
